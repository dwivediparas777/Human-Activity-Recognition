{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"HAR_LSTM.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"olegQPjAcLvK","colab_type":"code","colab":{}},"source":["# Importing Libraries"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXzESsq-cLvl","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYm1rRiMcLv8","colab_type":"code","colab":{}},"source":["# Activities are the class labels\n","# It is a 6 class classification\n","ACTIVITIES = {\n","    0: 'WALKING',\n","    1: 'WALKING_UPSTAIRS',\n","    2: 'WALKING_DOWNSTAIRS',\n","    3: 'SITTING',\n","    4: 'STANDING',\n","    5: 'LAYING',\n","}\n","\n","# Utility function to print the confusion matrix\n","def confusion_matrix(Y_true, Y_pred):\n","    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n","    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n","\n","    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nW14yFLmcLwN","colab_type":"text"},"source":["### Data"]},{"cell_type":"code","metadata":{"id":"v4r6cDCucLwT","colab_type":"code","colab":{}},"source":["# Data directory\n","DATADIR = 'UCI_HAR_Dataset'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgTiBa5KcLwh","colab_type":"code","colab":{}},"source":["# Raw data signals\n","# Signals are from Accelerometer and Gyroscope\n","# The signals are in x,y,z directions\n","# Sensor signals are filtered to have only body acceleration\n","# excluding the acceleration due to gravity\n","# Triaxial acceleration from the accelerometer is total acceleration\n","SIGNALS = [\n","    \"body_acc_x\",\n","    \"body_acc_y\",\n","    \"body_acc_z\",\n","    \"body_gyro_x\",\n","    \"body_gyro_y\",\n","    \"body_gyro_z\",\n","    \"total_acc_x\",\n","    \"total_acc_y\",\n","    \"total_acc_z\"\n","]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEvXUypscLwv","colab_type":"code","colab":{}},"source":["# Utility function to read the data from csv file\n","def _read_csv(filename):\n","    return pd.read_csv(filename, delim_whitespace=True, header=None)\n","\n","# Utility function to load the load\n","def load_signals(subset):\n","    signals_data = []\n","\n","    for signal in SIGNALS:\n","        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n","        signals_data.append(\n","            _read_csv(filename).as_matrix()\n","        ) \n","\n","    # Transpose is used to change the dimensionality of the output,\n","    # aggregating the signals by combination of sample/timestep.\n","    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n","    return np.transpose(signals_data, (1, 2, 0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDXRJzWCcLw6","colab_type":"code","colab":{}},"source":["\n","def load_y(subset):\n","    \"\"\"\n","    The objective that we are trying to predict is a integer, from 1 to 6,\n","    that represents a human activity. We return a binary representation of \n","    every sample objective as a 6 bits vector using One Hot Encoding\n","    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n","    \"\"\"\n","    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n","    y = _read_csv(filename)[0]\n","\n","    return pd.get_dummies(y).as_matrix()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9pDbXTOcLxG","colab_type":"code","colab":{}},"source":["def load_data():\n","    \"\"\"\n","    Obtain the dataset from multiple files.\n","    Returns: X_train, X_test, y_train, y_test\n","    \"\"\"\n","    X_train, X_test = load_signals('train'), load_signals('test')\n","    y_train, y_test = load_y('train'), load_y('test')\n","\n","    return X_train, X_test, y_train, y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"095J1Qq0cLxR","colab_type":"code","colab":{}},"source":["# Importing tensorflow\n","np.random.seed(42)\n","import tensorflow as tf\n","tf.set_random_seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"36AupLorcLxc","colab_type":"code","colab":{}},"source":["# Configuring a session\n","session_conf = tf.ConfigProto(\n","    intra_op_parallelism_threads=1,\n","    inter_op_parallelism_threads=1\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHOSP-QucLxq","colab_type":"code","colab":{}},"source":["# Import Keras\n","from keras import backend as K\n","sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n","K.set_session(sess)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDJdrw2rcLx0","colab_type":"code","colab":{}},"source":["# Importing libraries\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers.core import Dense, Dropout"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMVPNJkIcLx9","colab_type":"code","colab":{}},"source":["# Initializing parameters\n","epochs = 30\n","batch_size = 16\n","n_hidden = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLUYg9p1cLyG","colab_type":"code","colab":{}},"source":["# Utility function to count the number of classes\n","def _count_classes(y):\n","    return len(set([tuple(category) for category in y]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqqS9XmMcLyP","colab_type":"code","colab":{}},"source":["# Loading the train and test data\n","X_train, X_test, Y_train, Y_test = load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9UQO9HRcLyY","colab_type":"code","colab":{},"outputId":"01353ecc-9764-4dd5-da33-7a08fc2cd367"},"source":["timesteps = len(X_train[0])\n","input_dim = len(X_train[0][0])\n","n_classes = _count_classes(Y_train)\n","\n","print(timesteps)\n","print(input_dim)\n","print(len(X_train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["128\n","9\n","7352\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-qqNBAGzcLym","colab_type":"text"},"source":["- Defining the Architecture of LSTM"]},{"cell_type":"code","metadata":{"id":"crvIMGnycLyo","colab_type":"code","colab":{},"outputId":"35e1c87d-a4f5-407e-ee2b-cb13ff2cf00a"},"source":["# Initiliazing the sequential model\n","model = Sequential()\n","# Configuring the parameters\n","model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n","# Adding a dropout layer\n","model.add(Dropout(0.5))\n","# Adding a dense output layer with sigmoid activation\n","model.add(Dense(n_classes, activation='sigmoid'))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_3 (LSTM)                (None, 32)                5376      \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 6)                 198       \n","=================================================================\n","Total params: 5,574\n","Trainable params: 5,574\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wQNs07ZecLyx","colab_type":"code","colab":{}},"source":["# Compiling the model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MNTevCgHcLy6","colab_type":"code","colab":{},"outputId":"5fe19b3e-7e57-42df-b951-fe7608025fb4"},"source":["# Training the model\n","model.fit(X_train,\n","          Y_train,\n","          batch_size=batch_size,\n","          validation_data=(X_test, Y_test),\n","          epochs=epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 7352 samples, validate on 2947 samples\n","Epoch 1/30\n","7352/7352 [==============================] - 92s 13ms/step - loss: 1.3018 - acc: 0.4395 - val_loss: 1.1254 - val_acc: 0.4662\n","Epoch 2/30\n","7352/7352 [==============================] - 94s 13ms/step - loss: 0.9666 - acc: 0.5880 - val_loss: 0.9491 - val_acc: 0.5714\n","Epoch 3/30\n","7352/7352 [==============================] - 97s 13ms/step - loss: 0.7812 - acc: 0.6408 - val_loss: 0.8286 - val_acc: 0.5850\n","Epoch 4/30\n","7352/7352 [==============================] - 95s 13ms/step - loss: 0.6941 - acc: 0.6574 - val_loss: 0.7297 - val_acc: 0.6128\n","Epoch 5/30\n","7352/7352 [==============================] - 92s 13ms/step - loss: 0.6336 - acc: 0.6912 - val_loss: 0.7359 - val_acc: 0.6787\n","Epoch 6/30\n","7352/7352 [==============================] - 94s 13ms/step - loss: 0.5859 - acc: 0.7134 - val_loss: 0.7015 - val_acc: 0.6939\n","Epoch 7/30\n","7352/7352 [==============================] - 95s 13ms/step - loss: 0.5692 - acc: 0.7477 - val_loss: 0.5995 - val_acc: 0.7387\n","Epoch 8/30\n","7352/7352 [==============================] - 96s 13ms/step - loss: 0.4899 - acc: 0.7809 - val_loss: 0.5762 - val_acc: 0.7387\n","Epoch 9/30\n","7352/7352 [==============================] - 90s 12ms/step - loss: 0.4482 - acc: 0.7886 - val_loss: 0.7413 - val_acc: 0.7126\n","Epoch 10/30\n","7352/7352 [==============================] - 90s 12ms/step - loss: 0.4132 - acc: 0.8077 - val_loss: 0.5048 - val_acc: 0.7513\n","Epoch 11/30\n","7352/7352 [==============================] - 89s 12ms/step - loss: 0.3985 - acc: 0.8274 - val_loss: 0.5234 - val_acc: 0.7452\n","Epoch 12/30\n","7352/7352 [==============================] - 91s 12ms/step - loss: 0.3378 - acc: 0.8638 - val_loss: 0.4114 - val_acc: 0.8833\n","Epoch 13/30\n","7352/7352 [==============================] - 91s 12ms/step - loss: 0.2947 - acc: 0.9051 - val_loss: 0.4386 - val_acc: 0.8731\n","Epoch 14/30\n","7352/7352 [==============================] - 90s 12ms/step - loss: 0.2448 - acc: 0.9291 - val_loss: 0.3768 - val_acc: 0.8921\n","Epoch 15/30\n","7352/7352 [==============================] - 91s 12ms/step - loss: 0.2157 - acc: 0.9331 - val_loss: 0.4441 - val_acc: 0.8931\n","Epoch 16/30\n","7352/7352 [==============================] - 90s 12ms/step - loss: 0.2053 - acc: 0.9366 - val_loss: 0.4162 - val_acc: 0.8968\n","Epoch 17/30\n","7352/7352 [==============================] - 89s 12ms/step - loss: 0.2028 - acc: 0.9404 - val_loss: 0.4538 - val_acc: 0.8962\n","Epoch 18/30\n","7352/7352 [==============================] - 93s 13ms/step - loss: 0.1911 - acc: 0.9419 - val_loss: 0.3964 - val_acc: 0.8999\n","Epoch 19/30\n","7352/7352 [==============================] - 96s 13ms/step - loss: 0.1912 - acc: 0.9407 - val_loss: 0.3165 - val_acc: 0.9030\n","Epoch 20/30\n","7352/7352 [==============================] - 96s 13ms/step - loss: 0.1732 - acc: 0.9446 - val_loss: 0.4546 - val_acc: 0.8904\n","Epoch 21/30\n","7352/7352 [==============================] - 94s 13ms/step - loss: 0.1782 - acc: 0.9444 - val_loss: 0.3346 - val_acc: 0.9063\n","Epoch 22/30\n","7352/7352 [==============================] - 95s 13ms/step - loss: 0.1812 - acc: 0.9418 - val_loss: 0.8164 - val_acc: 0.8582\n","Epoch 23/30\n","7352/7352 [==============================] - 95s 13ms/step - loss: 0.1824 - acc: 0.9426 - val_loss: 0.4240 - val_acc: 0.9036\n","Epoch 24/30\n","7352/7352 [==============================] - 94s 13ms/step - loss: 0.1726 - acc: 0.9429 - val_loss: 0.4067 - val_acc: 0.9148\n","Epoch 25/30\n","7352/7352 [==============================] - 96s 13ms/step - loss: 0.1737 - acc: 0.9411 - val_loss: 0.3396 - val_acc: 0.9074\n","Epoch 26/30\n","7352/7352 [==============================] - 96s 13ms/step - loss: 0.1650 - acc: 0.9461 - val_loss: 0.3806 - val_acc: 0.9019\n","Epoch 27/30\n","7352/7352 [==============================] - 89s 12ms/step - loss: 0.1925 - acc: 0.9415 - val_loss: 0.6464 - val_acc: 0.8850\n","Epoch 28/30\n","7352/7352 [==============================] - 91s 12ms/step - loss: 0.1965 - acc: 0.9425 - val_loss: 0.3363 - val_acc: 0.9203\n","Epoch 29/30\n","7352/7352 [==============================] - 92s 12ms/step - loss: 0.1889 - acc: 0.9431 - val_loss: 0.3737 - val_acc: 0.9158\n","Epoch 30/30\n","7352/7352 [==============================] - 95s 13ms/step - loss: 0.1945 - acc: 0.9414 - val_loss: 0.3088 - val_acc: 0.9097\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x29b5ee36a20>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"I16SDHm1cLzD","colab_type":"code","colab":{},"outputId":"027c8a2a-841b-4fd1-9579-5928d9e9962d"},"source":["# Confusion Matrix\n","print(confusion_matrix(Y_test, model.predict(X_test)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n","True                                                                         \n","LAYING                 512        0        25        0                   0   \n","SITTING                  3      410        75        0                   0   \n","STANDING                 0       87       445        0                   0   \n","WALKING                  0        0         0      481                   2   \n","WALKING_DOWNSTAIRS       0        0         0        0                 382   \n","WALKING_UPSTAIRS         0        0         0        2                  18   \n","\n","Pred                WALKING_UPSTAIRS  \n","True                                  \n","LAYING                             0  \n","SITTING                            3  \n","STANDING                           0  \n","WALKING                           13  \n","WALKING_DOWNSTAIRS                38  \n","WALKING_UPSTAIRS                 451  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TwByaKrwcLzP","colab_type":"code","colab":{},"outputId":"ccf0243b-656c-47a6-8fe2-975c1119a7fb"},"source":["score = model.evaluate(X_test, Y_test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2947/2947 [==============================] - 4s 2ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TUwGAcyBcLzZ","colab_type":"code","colab":{},"outputId":"9061a691-c13f-4e8c-ce24-a5f733fc40b8"},"source":["score"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.3087582236972612, 0.9097387173396675]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"izKMn2HpcLzk","colab_type":"text"},"source":["- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n","- We can further imporve the performace with Hyperparameter tuning"]}]}